{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "060acc9d-73e1-4018-82e3-af694aab44f6",
   "metadata": {},
   "source": [
    "SONAR ROCK VS MINE PREDICTION WITH PYTHON\n",
    "#this is done using sonar data\n",
    "#####.ipynb-->python notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9eedfe-ca19-4e93-b8a8-07401ba8ae7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mines are the explosives that explodes when some object comes in contact \n",
    "#the submarine uses sonar that sends sound signals and receives it back. so this signal is used to decect wheather the object is mine or rock.\n",
    "#the machine learning algorithm used in this project is logistic regression model.\n",
    "#logistic regression works for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a52564-669e-436c-b047-5c65d1686ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORK FLOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6320ccb-c087-4afd-b038-2fe6cf183c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dependencies i.e libraries and functions\n",
    "#numpy is used for making arrays  \n",
    "import numpy as np\n",
    "#pandas is used for making dataframes\n",
    "import pandas as pd\n",
    "#matplotlib is used for making plots and graphs \n",
    "# import matplotlib.pyplot as plt\n",
    "#seaborn is lso used for plotting\n",
    "# import seaborn as sns\n",
    "#sklearn is a machine learning library from which we will get the datasets, machine learning algorithms and some functions\n",
    "#throuth this dataset module we can get data\n",
    "#Logistic Regression model is used for this project\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#train test split function is used to split our data into training data and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "#matrix module is used for evaluating our model\n",
    "#accuracy_score is used to find the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d575ba63-1071-43f2-98bd-a83d3c5dcfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data collection and data processing\n",
    "#loading the dataset to a pandas dataframe\n",
    "# since there is no header in the data, the header is given as none\n",
    "sonar_data = pd.read_csv('sonar_data.csv.zip',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c06bc2e6-9b04-4627-89cb-1bf2bbef49f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows and columns in this dataset\n",
    "sonar_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d5fa8c0-51ed-4daf-b63b-707b82b0976f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe represents the statistical measures of the data\n",
    "sonar_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "195ddc14-6441-44f9-9562-c87902bb5265",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60\n",
       "M    111\n",
       "R     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many examples for rock and mine\n",
    "#60 is written since the rock and mine is specified at 60th column\n",
    "sonar_data[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acfc308e-51b9-4913-9e56-0f38f73344f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#the examples for rock and mine is almost equal so our prediction will be accurate\n",
    "#this data have only 208 instances which is not sufficient for a machine learning model\n",
    "#if there is more data then the accuracy of the model is more \n",
    "#m-->mine\n",
    "#r-->rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed0fbb7-631f-4d20-960d-017f3add03bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.034989</td>\n",
       "      <td>0.045544</td>\n",
       "      <td>0.050720</td>\n",
       "      <td>0.064768</td>\n",
       "      <td>0.086715</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>0.128359</td>\n",
       "      <td>0.149832</td>\n",
       "      <td>0.213492</td>\n",
       "      <td>0.251022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>0.006930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.022498</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.041447</td>\n",
       "      <td>0.062028</td>\n",
       "      <td>0.096224</td>\n",
       "      <td>0.114180</td>\n",
       "      <td>0.117596</td>\n",
       "      <td>0.137392</td>\n",
       "      <td>0.159325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012311</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>0.008567</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.006024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "60                                                                         \n",
       "M   0.034989  0.045544  0.050720  0.064768  0.086715  0.111864  0.128359   \n",
       "R   0.022498  0.030303  0.035951  0.041447  0.062028  0.096224  0.114180   \n",
       "\n",
       "          7         8         9   ...        50        51        52        53  \\\n",
       "60                                ...                                           \n",
       "M   0.149832  0.213492  0.251022  ...  0.019352  0.016014  0.011643  0.012185   \n",
       "R   0.117596  0.137392  0.159325  ...  0.012311  0.010453  0.009640  0.009518   \n",
       "\n",
       "          54        55        56        57        58        59  \n",
       "60                                                              \n",
       "M   0.009923  0.008914  0.007825  0.009060  0.008695  0.006930  \n",
       "R   0.008567  0.007430  0.007814  0.006677  0.007078  0.006024  \n",
       "\n",
       "[2 rows x 60 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grouping data based on rock and mine\n",
    "sonar_data.groupby(60).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0acbb8cf-cd0f-4acf-8206-394f957fc98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#there is the difference between mine and rock so by using this difference we will predict wheather the object is rock or mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "824c62c7-29fc-41dd-86c3-e3012af3dc91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#seperate the data and the labels\n",
    "#data-->numericals in dataset (X)\n",
    "#labels-->60th column i.e rock and mine (categorical column) (Y)\n",
    "#if we are dropping a column then we should specify the axis\n",
    "#axis = 1 is given when the column is dropped\n",
    "#axis = 0 is given when the rows are dropped\n",
    "X = sonar_data.drop(columns = 60, axis = 1)\n",
    "Y = sonar_data[60]          \n",
    "#we are dropping 60th column from X and storing in Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22c00adf-8b07-4812-9261-266e2c896263",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0       1       2       3       4       5       6       7       8   \\\n",
      "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
      "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
      "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
      "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
      "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
      "\n",
      "         9   ...      50      51      52      53      54      55      56  \\\n",
      "0    0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
      "1    0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
      "2    0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
      "3    0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
      "4    0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
      "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "203  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n",
      "204  0.2154  ...  0.0051  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034   \n",
      "205  0.2529  ...  0.0155  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140   \n",
      "206  0.2354  ...  0.0042  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034   \n",
      "207  0.2354  ...  0.0181  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040   \n",
      "\n",
      "         57      58      59  \n",
      "0    0.0084  0.0090  0.0032  \n",
      "1    0.0049  0.0052  0.0044  \n",
      "2    0.0164  0.0095  0.0078  \n",
      "3    0.0044  0.0040  0.0117  \n",
      "4    0.0048  0.0107  0.0094  \n",
      "..      ...     ...     ...  \n",
      "203  0.0115  0.0193  0.0157  \n",
      "204  0.0032  0.0062  0.0067  \n",
      "205  0.0138  0.0077  0.0031  \n",
      "206  0.0079  0.0036  0.0048  \n",
      "207  0.0036  0.0061  0.0115  \n",
      "\n",
      "[208 rows x 60 columns]\n",
      "0      R\n",
      "1      R\n",
      "2      R\n",
      "3      R\n",
      "4      R\n",
      "      ..\n",
      "203    M\n",
      "204    M\n",
      "205    M\n",
      "206    M\n",
      "207    M\n",
      "Name: 60, Length: 208, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1703eff2-6367-4e6d-aafc-d0078e7fb381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split the data into training data and testing data\n",
    "#we should follow the order (data_train, data_test, label_train, label_test)\n",
    "#test_size=0.1 means 10% of the data to be test data. it can also be 0.2 based on the data\n",
    "#stratify is because we need to split the data based on the labels(Y). we want our dataset to split in the same proportion \n",
    "#random_state is used to split the data in a particular order. the number can be given accordingly. it is basically to reproduce the code as it is\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, stratify=Y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "338bfff4-ffb2-4489-b7bc-3957a2454950",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 60) (187, 60) (21, 60)\n"
     ]
    }
   ],
   "source": [
    "#checking how many training data and testing data are present\n",
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29f738fb-0320-4663-96ab-bbba3436ac1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0       1       2       3       4       5       6       7       8   \\\n",
      "115  0.0414  0.0436  0.0447  0.0844  0.0419  0.1215  0.2002  0.1516  0.0818   \n",
      "38   0.0123  0.0022  0.0196  0.0206  0.0180  0.0492  0.0033  0.0398  0.0791   \n",
      "56   0.0152  0.0102  0.0113  0.0263  0.0097  0.0391  0.0857  0.0915  0.0949   \n",
      "123  0.0270  0.0163  0.0341  0.0247  0.0822  0.1256  0.1323  0.1584  0.2017   \n",
      "18   0.0270  0.0092  0.0145  0.0278  0.0412  0.0757  0.1026  0.1138  0.0794   \n",
      "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "140  0.0412  0.1135  0.0518  0.0232  0.0646  0.1124  0.1787  0.2407  0.2682   \n",
      "5    0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
      "154  0.0117  0.0069  0.0279  0.0583  0.0915  0.1267  0.1577  0.1927  0.2361   \n",
      "131  0.1150  0.1163  0.0866  0.0358  0.0232  0.1267  0.2417  0.2661  0.4346   \n",
      "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
      "\n",
      "         9   ...      50      51      52      53      54      55      56  \\\n",
      "115  0.1975  ...  0.0222  0.0045  0.0136  0.0113  0.0053  0.0165  0.0141   \n",
      "38   0.0475  ...  0.0149  0.0125  0.0134  0.0026  0.0038  0.0018  0.0113   \n",
      "56   0.1504  ...  0.0048  0.0049  0.0041  0.0036  0.0013  0.0046  0.0037   \n",
      "123  0.2122  ...  0.0197  0.0189  0.0204  0.0085  0.0043  0.0092  0.0138   \n",
      "18   0.1520  ...  0.0045  0.0084  0.0010  0.0018  0.0068  0.0039  0.0120   \n",
      "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "140  0.2058  ...  0.0798  0.0376  0.0143  0.0272  0.0127  0.0166  0.0095   \n",
      "5    0.3039  ...  0.0104  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057   \n",
      "154  0.2169  ...  0.0039  0.0053  0.0029  0.0020  0.0013  0.0029  0.0020   \n",
      "131  0.5378  ...  0.0228  0.0099  0.0065  0.0085  0.0166  0.0110  0.0190   \n",
      "203  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n",
      "\n",
      "         57      58      59  \n",
      "115  0.0077  0.0246  0.0198  \n",
      "38   0.0058  0.0047  0.0071  \n",
      "56   0.0011  0.0034  0.0033  \n",
      "123  0.0094  0.0105  0.0093  \n",
      "18   0.0132  0.0070  0.0088  \n",
      "..      ...     ...     ...  \n",
      "140  0.0225  0.0098  0.0085  \n",
      "5    0.0027  0.0051  0.0062  \n",
      "154  0.0062  0.0026  0.0052  \n",
      "131  0.0141  0.0068  0.0086  \n",
      "203  0.0115  0.0193  0.0157  \n",
      "\n",
      "[187 rows x 60 columns]\n",
      "115    M\n",
      "38     R\n",
      "56     R\n",
      "123    M\n",
      "18     R\n",
      "      ..\n",
      "140    M\n",
      "5      R\n",
      "154    M\n",
      "131    M\n",
      "203    M\n",
      "Name: 60, Length: 187, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d72edecd-a5db-47f3-bfb4-ecd04707ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the data is not in order since we use train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5bfdfd18-06f1-4a2a-9a69-62c4fb93ff4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#training the model (using logistic regression)\n",
    "#loading the logistic regression function into the variable model\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ac15968-8815-49a4-b098-15912ae5d221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the logistic regression model with training data\n",
    "#model.fit will be training the model with the training data. fit() method is used to train the model\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3961d045-c0eb-45ce-8caa-57fc4006a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if u are having lot of data and training lot of data like neural network then it will take lot of time for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "780e8878-173c-413e-9744-0d2eadd80d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model evaluation\n",
    "#finding the accuracy for training data\n",
    "#finding the accuracy for test data\n",
    "#in most of the cases the accuracy of training data will be more (since the model already seen this data) than the accuracy of test data\n",
    "#the accuracy of the model should be more than 70% then the model is good and the accuracy of the model will also depend on the data you use\n",
    "X_train_prediction = model.predict(X_train)\n",
    "#X_train_prediction is the prediction of our model is compaared with original labels\n",
    "#Y_train is the original labels of the instance\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1885938a-1dcf-4db8-b8e9-d0f702dd43dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data :  0.8342245989304813\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37b63387-cd9e-40e3-a078-cbd7a3f7a7eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#finding the accuracy for test data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48dc1845-8749-48b7-b3ca-12edb879e80f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data :  0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb004211-2cf9-4f31-b985-122936df257f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R']\n",
      "The object is a Rock\n"
     ]
    }
   ],
   "source": [
    "#making a predictive system that predicts wheather the object is rock or mine using sonar data\n",
    "input_data = (0.0291,0.0400,0.0771,0.0809,0.0521,0.1051,0.0145,0.0674,0.1294,0.1146,0.0942,0.0794,0.0252,0.1191,0.1045,0.2050,0.1556,0.2690,0.3784,0.4024,0.3470,0.1395,0.1208,0.2827,0.1500,0.2626,0.4468,0.7520,0.9036,0.7812,0.4766,0.2483,0.5372,0.6279,0.3647,0.4572,0.6359,0.6474,0.5520,0.3253,0.2292,0.0653,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0056,0.0237,0.0204,0.0050,0.0137,0.0164,0.0081,0.0139,0.0111)\n",
    "#changing the input_data to numpy array (list to numpy array)\n",
    "#the processing in numpy array is faster and more easy\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "#reshape the numpy array as we are predicting for one instance\n",
    "#1,-1 represents that there is one instance and we need to predict one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "#input_data_reshaped contain the features of the data\n",
    "prediction = model.predict(input_data_reshaped)\n",
    "print(prediction)\n",
    "#0 represent the first element of list\n",
    "#using the first element the model will predict wheather the object is rock or mine\n",
    "if (prediction[0]=='R'):\n",
    "    print('The object is a Rock')\n",
    "else:\n",
    "    print('The object is a Mine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
